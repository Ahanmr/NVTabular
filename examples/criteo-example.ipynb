{
 "cells": [
   {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criteo Example \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear cache\n",
    "!sync; echo 3 > /proc/sys/vm/drop_caches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "GPU_id = 2\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(GPU_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/numba/cuda/envvars.py:17: NumbaWarning: \n",
      "Environment variables with the 'NUMBAPRO' prefix are deprecated and consequently ignored, found use of NUMBAPRO_NVVM=/usr/local/cuda/nvvm/lib64/libnvvm.so.\n",
      "\n",
      "For more information about alternatives visit: ('http://numba.pydata.org/numba-doc/latest/cuda/overview.html', '#cudatoolkit-lookup')\n",
      "  warnings.warn(errors.NumbaWarning(msg))\n",
      "/opt/conda/lib/python3.6/site-packages/numba/cuda/envvars.py:17: NumbaWarning: \n",
      "Environment variables with the 'NUMBAPRO' prefix are deprecated and consequently ignored, found use of NUMBAPRO_LIBDEVICE=/usr/local/cuda/nvvm/libdevice/.\n",
      "\n",
      "For more information about alternatives visit: ('http://numba.pydata.org/numba-doc/latest/cuda/overview.html', '#cudatoolkit-lookup')\n",
      "  warnings.warn(errors.NumbaWarning(msg))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time \n",
    "\n",
    "from fastai import *\n",
    "from fastai.basic_data import *\n",
    "from fastai.basic_data import *\n",
    "from fastai.tabular import *\n",
    "from fastai.basic_data import DataBunch\n",
    "from fastai.tabular import TabularModel\n",
    "import rmm\n",
    "import cudf\n",
    "import nvtabular as nvt\n",
    "from nvtabular.ops import Normalize, FillMissing, Categorify, Moments, Median, Encoder, LogOp, ZeroFill\n",
    "from nvtabular.torch_dataloader import FileItrDataset, DLCollator, DLDataLoader\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmm.reinitialize(pool_allocator=True, initial_pool_size=0.8 * rmm.get_info().free)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <h3> Dataset Gathering: Define files in the training and validation datasets. </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# data_path = '/rapids/notebooks/jperez/Documents/ds-itr/examples/'\n",
    "data_path = '/raid/criteo/tests/crit_int_pq/'\n",
    "#df_test = 'test/'\n",
    "df_valid = ''\n",
    "df_train = ''\n",
    "start = 0\n",
    "split = 23\n",
    "end = 24\n",
    "\n",
    "train_days = [x for x in range(start, split)]\n",
    "valid_days = [x for x in range(split, end)]\n",
    "# print(train_days, valid_days)\n",
    "\n",
    "train_set = [data_path + df_train + x for x in os.listdir(data_path + df_train) if  x.endswith('parquet') and int(x.split(\".\")[0].split('_')[1]) in train_days]\n",
    "valid_set = [data_path + df_valid + x for x in os.listdir(data_path + df_valid) if  x.endswith('parquet') and int(x.split(\".\")[0].split('_')[1]) in valid_days]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['/raid/criteo/tests/crit_int_pq/day_5.parquet',\n",
       "  '/raid/criteo/tests/crit_int_pq/day_19.parquet',\n",
       "  '/raid/criteo/tests/crit_int_pq/day_2.parquet',\n",
       "  '/raid/criteo/tests/crit_int_pq/day_22.parquet',\n",
       "  '/raid/criteo/tests/crit_int_pq/day_16.parquet',\n",
       "  '/raid/criteo/tests/crit_int_pq/day_3.parquet',\n",
       "  '/raid/criteo/tests/crit_int_pq/day_8.parquet',\n",
       "  '/raid/criteo/tests/crit_int_pq/day_17.parquet',\n",
       "  '/raid/criteo/tests/crit_int_pq/day_7.parquet',\n",
       "  '/raid/criteo/tests/crit_int_pq/day_12.parquet',\n",
       "  '/raid/criteo/tests/crit_int_pq/day_13.parquet',\n",
       "  '/raid/criteo/tests/crit_int_pq/day_10.parquet',\n",
       "  '/raid/criteo/tests/crit_int_pq/day_15.parquet',\n",
       "  '/raid/criteo/tests/crit_int_pq/day_9.parquet',\n",
       "  '/raid/criteo/tests/crit_int_pq/day_18.parquet',\n",
       "  '/raid/criteo/tests/crit_int_pq/day_14.parquet',\n",
       "  '/raid/criteo/tests/crit_int_pq/day_20.parquet',\n",
       "  '/raid/criteo/tests/crit_int_pq/day_1.parquet',\n",
       "  '/raid/criteo/tests/crit_int_pq/day_11.parquet',\n",
       "  '/raid/criteo/tests/crit_int_pq/day_21.parquet',\n",
       "  '/raid/criteo/tests/crit_int_pq/day_4.parquet',\n",
       "  '/raid/criteo/tests/crit_int_pq/day_6.parquet',\n",
       "  '/raid/criteo/tests/crit_int_pq/day_0.parquet'],\n",
       " ['/raid/criteo/tests/crit_int_pq/day_23.parquet'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set, valid_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Grab column information</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['C1',\n",
       "  'C2',\n",
       "  'C3',\n",
       "  'C4',\n",
       "  'C5',\n",
       "  'C6',\n",
       "  'C7',\n",
       "  'C8',\n",
       "  'C9',\n",
       "  'C10',\n",
       "  'C11',\n",
       "  'C12',\n",
       "  'C13',\n",
       "  'C14',\n",
       "  'C15',\n",
       "  'C16',\n",
       "  'C17',\n",
       "  'C18',\n",
       "  'C19',\n",
       "  'C20',\n",
       "  'C21',\n",
       "  'C22',\n",
       "  'C23',\n",
       "  'C24',\n",
       "  'C25',\n",
       "  'C26'],\n",
       " ['I1',\n",
       "  'I2',\n",
       "  'I3',\n",
       "  'I4',\n",
       "  'I5',\n",
       "  'I6',\n",
       "  'I7',\n",
       "  'I8',\n",
       "  'I9',\n",
       "  'I10',\n",
       "  'I11',\n",
       "  'I12',\n",
       "  'I13'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cont_names = ['I' + str(x) for x in range(1,14)]\n",
    "cat_names =  ['C' + str(x) for x in range(1,27)]\n",
    "cat_names, cont_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['label',\n",
       " 'I1',\n",
       " 'I2',\n",
       " 'I3',\n",
       " 'I4',\n",
       " 'I5',\n",
       " 'I6',\n",
       " 'I7',\n",
       " 'I8',\n",
       " 'I9',\n",
       " 'I10',\n",
       " 'I11',\n",
       " 'I12',\n",
       " 'I13',\n",
       " 'C1',\n",
       " 'C2',\n",
       " 'C3',\n",
       " 'C4',\n",
       " 'C5',\n",
       " 'C6',\n",
       " 'C7',\n",
       " 'C8',\n",
       " 'C9',\n",
       " 'C10',\n",
       " 'C11',\n",
       " 'C12',\n",
       " 'C13',\n",
       " 'C14',\n",
       " 'C15',\n",
       " 'C16',\n",
       " 'C17',\n",
       " 'C18',\n",
       " 'C19',\n",
       " 'C20',\n",
       " 'C21',\n",
       " 'C22',\n",
       " 'C23',\n",
       " 'C24',\n",
       " 'C25',\n",
       " 'C26']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['label']  + cont_names + cat_names\n",
    "cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Preprocessing:</h3> <p>Select operations to perform, create the Preprocessor object, create dataset iterator object and collect the stats on the training dataset</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 29 µs, sys: 19 µs, total: 48 µs\n",
      "Wall time: 58.9 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "proc = nvt.Workflow(cat_names=cat_names, cont_names=cont_names, label_name=['label'], to_cpu=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 63 µs, sys: 40 µs, total: 103 µs\n",
      "Wall time: 114 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "proc.add_cont_feature([ZeroFill(replace=True), LogOp(replace=True)])\n",
    "proc.add_cont_preprocess(Normalize(replace=True))\n",
    "proc.add_cat_preprocess(Categorify(replace=True, use_frequency=True, freq_threshold=15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14 µs, sys: 9 µs, total: 23 µs\n",
      "Wall time: 33.4 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trains_itrs = nvt.dataset(train_set, engine='parquet', gpu_memory_frac=0.4)\n",
    "valids_itrs = nvt.dataset(valid_set, engine='parquet', gpu_memory_frac=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = '/raid/criteo/tests/demo_out'\n",
    "output_train = os.path.join(out, 'train/')\n",
    "output_valid = os.path.join(out, 'valid/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17min 18s, sys: 9min 44s, total: 27min 3s\n",
      "Wall time: 21min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "proc.apply(trains_itrs, apply_offline=True, record_stats=True, shuffle=True, output_path=output_train, num_out_files=35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 27.4 s, sys: 18.6 s, total: 46 s\n",
      "Wall time: 33.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "proc.apply(valids_itrs, apply_offline=True, record_stats=False, shuffle=True, output_path=output_valid, num_out_files=35)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Preprocessing Complete<4>\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Model Setup<h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_set = [os.path.join(output_train, x) for x in os.listdir(output_train) if x.endswith(\"parquet\")]\n",
    "new_valid_set = [os.path.join(output_valid, x) for x in os.listdir(output_valid) if x.endswith(\"parquet\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmm.reinitialize(pool_allocator=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Gather embeddings using statistics gathered in the Read phase.</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = [x[1] for x in proc.df_ops['Categorify'].get_emb_sz(proc.stats[\"categories\"], proc.columns_ctx['categorical']['base'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Create the file iterators using the FileItrDataset Class.</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "t_batch_sets = [FileItrDataset(x, names=cols, engine='parquet', batch_size=1600000, sep=\"\\t\") for x in new_train_set]\n",
    "v_batch_sets = [FileItrDataset(x, names=cols, engine='parquet', batch_size=1600000, sep=\"\\t\") for x in new_valid_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "t_chain = torch.utils.data.ChainDataset(t_batch_sets)\n",
    "v_chain = torch.utils.data.ChainDataset(v_batch_sets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Use the Deep Learning Collator to create a collate function to pass to the dataloader.</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dlc = DLCollator(preproc=proc, apply_ops=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "t_data = DLDataLoader(t_chain, collate_fn=dlc.gdf_col, pin_memory=False, num_workers=0)\n",
    "v_data = DLDataLoader(v_chain, collate_fn=dlc.gdf_col, pin_memory=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>After creating the Dataloaders you can leverage fastai framework to create Machine Learning models</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "databunch = DataBunch(t_data, v_data, collate_fn=dlc.gdf_col, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model = TabularModel(emb_szs = embeddings, n_cont=len(cont_names), out_sz=2, layers=[512,256])\n",
    "\n",
    "learn =  Learner(databunch, model, metrics=[accuracy])\n",
    "learn.loss_func = torch.nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot(show_moms=True, suggestion=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1.32e-2\n",
    "epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time()\n",
    "learn.fit_one_cycle(epochs,learning_rate)\n",
    "t_final = time() - start "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### "
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
