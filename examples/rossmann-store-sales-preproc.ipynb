{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing the Rossmann Store Sales Dataset\n",
    "Here we implement some feature engineering outlined by FastAI in [their example solution](https://github.com/fastai/fastai/blob/master/courses/dl1/lesson3-rossman.ipynb) to the [Kaggle Rossmann Store Sales competition](https://www.kaggle.com/c/rossmann-store-sales). We've simplified some sections and left out most of the documentation to keep things neat, so feel free to consult the original notebook for explanations of the feature engineering going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DATA_DIR = os.environ.get('INPUT_DATA_DIR', '/tmp/rossmann')\n",
    "OUTPUT_DATA_DIR = os.environ.get('DATA_DIR', '/data')\n",
    "VALID_FRAC = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-05-11 22:13:57--  http://files.fast.ai/part2/lesson14/rossmann.tgz\n",
      "Resolving files.fast.ai (files.fast.ai)... 67.205.15.147\n",
      "Connecting to files.fast.ai (files.fast.ai)|67.205.15.147|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 7730448 (7.4M) [application/x-gtar-compressed]\n",
      "Saving to: ‘/tmp/rossmann/rossmann.tgz’\n",
      "\n",
      "/tmp/rossmann/rossm 100%[===================>]   7.37M  8.60MB/s    in 0.9s    \n",
      "\n",
      "2020-05-11 22:13:58 (8.60 MB/s) - ‘/tmp/rossmann/rossmann.tgz’ saved [7730448/7730448]\n",
      "\n",
      "googletrend.csv        state_names.csv\t test.csv\n",
      "rossmann.tgz\t       store.csv\t train.csv\n",
      "sample_submission.csv  store_states.csv  weather.csv\n"
     ]
    }
   ],
   "source": [
    "! mkdir -p $INPUT_DATA_DIR\n",
    "! wget -O $INPUT_DATA_DIR/rossmann.tgz http://files.fast.ai/part2/lesson14/rossmann.tgz\n",
    "! cd $INPUT_DATA_DIR && tar -xzf rossmann.tgz && ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_table(table_name):\n",
    "    return pd.read_csv(os.path.join(INPUT_DATA_DIR, f'{table_name}.csv'), low_memory=False)\n",
    "\n",
    "train = read_table('train')\n",
    "store = read_table('store')\n",
    "store_states = read_table('store_states')\n",
    "state_names = read_table('state_names')\n",
    "googletrend = read_table('googletrend')\n",
    "weather = read_table('weather')\n",
    "test = read_table('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.StateHoliday = train.StateHoliday!='0'\n",
    "test.StateHoliday = test.StateHoliday!='0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "googletrend['Date'] = googletrend.week.str.split(' - ', expand=True)[0]\n",
    "googletrend['State'] = googletrend.file.str.split('_', expand=True)[2]\n",
    "googletrend.loc[googletrend.State=='NI', \"State\"] = 'HB,NI'\n",
    "\n",
    "trend_de = googletrend.loc[googletrend.file == 'Rossmann_DE'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in (weather, googletrend, train, test, trend_de):\n",
    "    df.loc[:, 'Date'] = pd.to_datetime(df.Date)\n",
    "    df['Year'] = df.Date.dt.year\n",
    "    df['Month'] = df.Date.dt.month\n",
    "    df['Week'] = df.Date.dt.week\n",
    "    df['Day'] = df.Date.dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick extension for handling left merges succinctly\n",
    "@pd.api.extensions.register_dataframe_accessor('left')\n",
    "class LeftMerger:\n",
    "    def __init__(self, pandas_obj):\n",
    "        self._obj = pandas_obj\n",
    "\n",
    "    def merge(self, right, left_on, right_on=None, suffix=None):\n",
    "        df = self._obj.merge(\n",
    "            right, how='left', left_on=left_on, right_on=right_on or left_on, suffixes=('', suffix or '_y'))\n",
    "        if suffix is None:\n",
    "            return df.drop(columns=df.filter(regex='_y$').columns.tolist())\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = weather.left.merge(state_names, 'file', right_on='StateName')\n",
    "store = store.left.merge(store_states, 'Store', right_on='Store')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train.left.merge(store, 'Store')\n",
    "test_df = test.left.merge(store, 'Store')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.left.merge(googletrend, ['State', 'Year', 'Week'])\n",
    "test_df = test_df.left.merge(googletrend, ['State', 'Year', 'Week'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.left.merge(trend_de, ['Year', 'Week'], suffix='_DE')\n",
    "test_df = test_df.left.merge(trend_de, ['Year', 'Week'], suffix='_DE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.left.merge(weather, ['State', 'Date'])\n",
    "test_df = test_df.left.merge(weather, ['State', 'Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [train_df, test_df]:\n",
    "    df['CompetitionOpenSinceYear'] = df.CompetitionOpenSinceYear.fillna(1900).astype(np.int32)\n",
    "    df['CompetitionOpenSinceMonth'] = df.CompetitionOpenSinceMonth.fillna(1).astype(np.int32)\n",
    "    df['Promo2SinceYear'] = df.Promo2SinceYear.fillna(1900).astype(np.int32)\n",
    "    df['Promo2SinceWeek'] = df.Promo2SinceWeek.fillna(1).astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [train_df, test_df]:\n",
    "    df[\"CompetitionOpenSince\"] = pd.to_datetime(dict(year=df.CompetitionOpenSinceYear, \n",
    "                                                     month=df.CompetitionOpenSinceMonth, day=15))\n",
    "    df[\"CompetitionDaysOpen\"] = df.Date.subtract(df.CompetitionOpenSince).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [train_df, test_df]:\n",
    "    df.loc[df.CompetitionDaysOpen<0, \"CompetitionDaysOpen\"] = 0\n",
    "    df.loc[df.CompetitionOpenSinceYear<1990, \"CompetitionDaysOpen\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [train_df, test_df]:\n",
    "    df[\"CompetitionMonthsOpen\"] = df[\"CompetitionDaysOpen\"]//30\n",
    "    df.loc[df.CompetitionMonthsOpen>24, \"CompetitionMonthsOpen\"] = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [train_df, test_df]:\n",
    "    dt = pd.to_datetime(df.Promo2SinceYear, format='%Y').astype(np.int64) // 10**9\n",
    "    dt += 7*24*3600*df.Promo2SinceWeek\n",
    "    df[\"Promo2Since\"] = pd.to_datetime(dt*10**9)\n",
    "    df[\"Promo2Days\"] = df.Date.subtract(df[\"Promo2Since\"]).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [train_df, test_df]:\n",
    "    df.loc[df.Promo2Days<0, \"Promo2Days\"] = 0\n",
    "    df.loc[df.Promo2SinceYear<1990, \"Promo2Days\"] = 0\n",
    "    df[\"Promo2Weeks\"] = df[\"Promo2Days\"]//7\n",
    "    df.loc[df.Promo2Weeks<0, \"Promo2Weeks\"] = 0\n",
    "    df.loc[df.Promo2Weeks>25, \"Promo2Weeks\"] = 25\n",
    "    df.Promo2Weeks.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/conda/envs/rapids/lib/python3.7/site-packages/pandas/core/frame.py:7138: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort,\n"
     ]
    }
   ],
   "source": [
    "df = train_df.append(test_df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ops: masking, ffill, bfill, timedelta\n",
    "df = df.sort_values(by=['Store', 'Date'])\n",
    "\n",
    "# first build a mask indicating where stores start and end\n",
    "first_indices = df.Store.diff() != 0\n",
    "last_indices = df.Store.diff().iloc[1:].append(pd.Series([1]))\n",
    "last_indices.index = first_indices.index\n",
    "idx_mask = ~(first_indices | last_indices)\n",
    "\n",
    "event_fields = ['SchoolHoliday', 'StateHoliday', 'Promo']\n",
    "for field in event_fields:\n",
    "    # use the mask from above to mask save dates from the start and end\n",
    "    # of a given store's range, as well as all dates that have an event\n",
    "    df['tmp'] = df.Date\n",
    "    df.loc[(df[field] == 0) & idx_mask, 'tmp'] = np.nan\n",
    "\n",
    "    # then use ffill and bbfill to give the input to the time delta\n",
    "    df['After'+field] = df.tmp.ffill()\n",
    "    df['Before'+field] = df.tmp.bfill()\n",
    "\n",
    "    # compute deltas between bfilled and ffilled dates and the current date\n",
    "    df['After'+field] = (df['Date'] - df['After'+field]).astype('timedelta64[D]')\n",
    "    df['Before'+field] = (df['Before'+field] - df['Date']).astype('timedelta64[D]')\n",
    "\n",
    "# get rid of our dummy column\n",
    "df = df.drop(columns=['tmp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.set_index(\"Date\")\n",
    "bwd = df[['Store']+event_fields].sort_index().groupby(\"Store\").rolling(7, min_periods=1).sum()\n",
    "fwd = df[['Store']+event_fields].sort_index(ascending=False).groupby(\"Store\").rolling(7, min_periods=1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in (bwd, fwd):\n",
    "    d.drop('Store', 1, inplace=True)\n",
    "    d.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d, suffix in zip([bwd, fwd], ['_bw', '_fw']):\n",
    "    df = df.left.merge(d, ['Store', 'Date'], suffix=suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.left.merge(df, ['Store', 'Date'])\n",
    "test_df = test_df.left.merge(df, ['Store', 'Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df[train_df.Sales != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.sort_values(by='Date')\n",
    "num_valid = int(VALID_FRAC*len(train_df))\n",
    "valid_df = train_df[-num_valid:]\n",
    "train_df = train_df[:-num_valid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(os.path.join(OUTPUT_DATA_DIR, 'train.csv'), index=False)\n",
    "valid_df.to_csv(os.path.join(OUTPUT_DATA_DIR, 'valid.csv'), index=False)\n",
    "test_df.to_csv(os.path.join(OUTPUT_DATA_DIR, 'test.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
